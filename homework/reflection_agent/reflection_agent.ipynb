{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# 在 LangSmith 中添加追踪功能\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Reflection\"\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a writing assistant tasked with creating well-crafted, coherent, and engaging articles based on the user's request.\"\n",
    "            \" Focus on clarity, structure, and quality to produce the best possible piece of writing.\"\n",
    "            \" If the user provides feedback or suggestions, revise and improve the writing to better align with their expectations.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = writer_prompt | ChatOllama(\n",
    "    model=\"llama3.1:8b-instruct-q8_0\",\n",
    "    max_tokens=8192,\n",
    "    temperature=1.2,\n",
    ")\n",
    "\n",
    "article = \"\"\n",
    "\n",
    "topic = HumanMessage(\n",
    "    content=\"参考水浒传的风格，改写吴承恩的西游记中任意篇章\"\n",
    ")\n",
    "\n",
    "for chunk in writer.stream({\"messages\": [topic]}):\n",
    "    print(chunk.content, end=\"\")\n",
    "    article += chunk.content\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 使用Markdown显示优化后的格式\n",
    "display(Markdown(article))\n",
    "\n",
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a teacher grading an article submission. writer critique and recommendations for the user's submission.\"\n",
    "            \" Provide detailed recommendations, including requests for length, depth, style, etc.\",\n",
    "\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reflect = reflection_prompt | ChatOllama(\n",
    "    model=\"llama3.1:8b-instruct-q8_0\",\n",
    "    max_tokens=8192,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "reflection = \"\"\n",
    "\n",
    "# 将主题（topic）和生成的文章（article）作为输入发送给反思智能体\n",
    "for chunk in reflect.stream({\"messages\": [topic, HumanMessage(content=article)]}):\n",
    "    print(chunk.content, end=\"\")\n",
    "    reflection += chunk.content\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 使用Markdown显示优化后的格式\n",
    "display(Markdown(reflection))\n",
    "\n",
    "from typing import Annotated  # 用于类型注解\n",
    "from langgraph.graph import END, StateGraph, START  # 导入状态图的相关常量和类\n",
    "from langgraph.graph.message import add_messages  # 用于在状态中处理消息\n",
    "from langgraph.checkpoint.memory import MemorySaver  # 内存保存机制，用于保存检查点\n",
    "from typing_extensions import TypedDict  # 用于定义带有键值对的字典类型\n",
    "\n",
    "# 定义状态类，使用TypedDict以保存消息\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]  # 使用注解确保消息列表使用add_messages方法处理\n",
    "\n",
    "# 异步生成节点函数：生成内容（如作文）\n",
    "# 输入状态，输出包含新生成消息的状态\n",
    "async def generation_node(state: State) -> State:\n",
    "    # 调用生成器(writer)，并将消息存储到新的状态中返回\n",
    "    return {\"messages\": [await writer.ainvoke(state['messages'])]}\n",
    "\n",
    "# 异步反思节点函数：对生成的内容进行反思和反馈\n",
    "# 输入状态，输出带有反思反馈的状态\n",
    "async def reflection_node(state: State) -> State:\n",
    "    # 创建一个消息类型映射，ai消息映射为HumanMessage，human消息映射为AIMessage\n",
    "    cls_map = {\"ai\": HumanMessage, \"human\": AIMessage}\n",
    "\n",
    "    # 处理消息，保持用户的原始请求（第一个消息），转换其余消息的类型\n",
    "    translated = [state['messages'][0]] + [\n",
    "        cls_map[msg.type](content=msg.content) for msg in state['messages'][1:]\n",
    "    ]\n",
    "\n",
    "    # 调用反思器(reflect)，将转换后的消息传入，获取反思结果\n",
    "    res = await reflect.ainvoke(translated)\n",
    "\n",
    "    # 返回新的状态，其中包含反思后的消息\n",
    "    return {\"messages\": [HumanMessage(content=res.content)]}\n",
    "\n",
    "MAX_ROUND = 6\n",
    "\n",
    "# 定义条件函数，决定是否继续反思过程\n",
    "# 如果消息数量超过6条，则终止流程\n",
    "def should_continue(state: State):\n",
    "    if len(state[\"messages\"]) > MAX_ROUND:\n",
    "        return END  # 达到条件时，流程结束\n",
    "    return \"reflect\"  # 否则继续进入反思节点\n",
    "\n",
    "# 创建状态图，传入初始状态结构\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# 在状态图中添加\"writer\"节点，节点负责生成内容\n",
    "builder.add_node(\"writer\", generation_node)\n",
    "\n",
    "# 在状态图中添加\"reflect\"节点，节点负责生成反思反馈\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "\n",
    "# 定义起始状态到\"writer\"节点的边，从起点开始调用生成器\n",
    "builder.add_edge(START, \"writer\")\n",
    "\n",
    "\n",
    "# 在\"writer\"节点和\"reflect\"节点之间添加条件边\n",
    "# 判断是否需要继续反思，或者结束\n",
    "builder.add_conditional_edges(\"writer\", should_continue)\n",
    "\n",
    "# 添加从\"reflect\"节点回到\"writer\"节点的边，进行反复的生成-反思循环\n",
    "builder.add_edge(\"reflect\", \"writer\")\n",
    "\n",
    "# 创建内存保存机制，允许在流程中保存中间状态和检查点\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 编译状态图，使用检查点机制\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# 可视化图\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(\n",
    "            graph.get_graph(xray=True).draw_mermaid_png()\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error generating graph: {e}\")\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 定义装饰器，记录函数调用次数\n",
    "def track_steps(func):\n",
    "    step_counter = {'count': 0}  # 用于记录调用次数\n",
    "\n",
    "    def wrapper(event, *args, **kwargs):\n",
    "        # 增加调用次数\n",
    "        step_counter['count'] += 1\n",
    "        # 在函数调用之前打印 step\n",
    "        display(Markdown(f\"## Round {step_counter['count']}\"))\n",
    "        # 调用原始函数\n",
    "        return func(event, *args, **kwargs)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "# 使用装饰器装饰 pretty_print_event_markdown 函数\n",
    "@track_steps\n",
    "def pretty_print_event_markdown(event):\n",
    "    # 如果是生成写作部分\n",
    "    if 'writer' in event:\n",
    "        generate_md = \"#### 写作生成:\\n\"\n",
    "        for message in event['writer']['messages']:\n",
    "            generate_md += f\"- {message.content}\\n\"\n",
    "        display(Markdown(generate_md))\n",
    "\n",
    "    # 如果是反思评论部分\n",
    "    if 'reflect' in event:\n",
    "        reflect_md = \"#### 评论反思:\\n\"\n",
    "        for message in event['reflect']['messages']:\n",
    "            reflect_md += f\"- {message.content}\\n\"\n",
    "        display(Markdown(reflect_md))\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"参考西游记唐僧的说话风格，写一篇奉劝年轻人努力工作的文章\")\n",
    "    ],\n",
    "}\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "async for event in graph.astream(inputs, config):\n",
    "    pretty_print_event_markdown(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
